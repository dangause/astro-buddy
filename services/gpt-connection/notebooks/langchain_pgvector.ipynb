{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Run export OPENAI_API_KEY=sk-YOUR_OPENAI_API_KEY...\n",
    "# Get openAI api key by reading local .env file\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "dotenv_path = os.path.abspath('../../../.env')\n",
    "_ = load_dotenv(dotenv_path)\n",
    "OPENAI_API_KEY  = os.environ['OPENAI_API_KEY']\n",
    "PG_DB_PW = os.environ['POSTGRES_DB_PASSWORD']\n",
    "host= os.environ['POSTGRES_DB_HOST']\n",
    "port= os.environ['POSTGRES_DB_PORT']\n",
    "user= os.environ['POSTGRES_DB_USER']\n",
    "password= os.environ['POSTGRES_DB_PASSWORD']\n",
    "dbname= os.environ['POSTGRES_DB_DBNAME']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/l2klswfj1wvcw_vbmvvbc70h0000gn/T/ipykernel_23964/3406201478.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import tiktoken\n",
    "import psycopg2\n",
    "import ast\n",
    "import pgvector\n",
    "import math\n",
    "from psycopg2.extras import execute_values\n",
    "from pgvector.psycopg2 import register_vector\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from langchain.vectorstores.pgvector import PGVector\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain_openai import ChatOpenAI, OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONNECTION_STRING = f\"postgresql://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "# CONNECTION_STRING = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{dbname}?sslmode=require\"\n",
    "CONNECTION_STRING = f\"postgresql://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "collection_name= \"arxiv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host=host,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    password=PG_DB_PW,\n",
    "    database=dbname\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgreSQL database in Timescale using connection string\n",
    "conn = psycopg2.connect(CONNECTION_STRING)\n",
    "cur = conn.cursor()\n",
    "\n",
    "#install pgvector\n",
    "cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\");\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df = pd.read_csv('../../data-ingest/data/embeddings/test_embedding.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load documents from Pandas dataframe for insertion into database\n",
    "from langchain.document_loaders import DataFrameLoader\n",
    "\n",
    "# page_content_column is the column name in the dataframe to create embeddings for\n",
    "loader = DataFrameLoader(embedding_df, page_content_column = 'content')\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OpenAIEmbeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAIEmbeddings\u001b[49m()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'OpenAIEmbeddings' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores.pgvector import DistanceStrategy\n",
    "\n",
    "db = PGVector.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embeddings,\n",
    "    collection_name=collection_name,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    "    pre_delete_collection=False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PGVector.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# Query for which we want to find semantically similar documents\n",
    "query = \"What is a quasar?\"\n",
    "\n",
    "#Fetch the k=3 most similar documents\n",
    "docs =  db.similarity_search(query, k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever from database\n",
    "# We specify the number of results we want to retrieve (k=3)\n",
    "retriever = db.as_retriever(\n",
    "    search_kwargs={\"k\": 3}\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature = 0.0, model = 'gpt-3.5-turbo-16k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa_stuff = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"What is a quasar?\"\n",
    "\n",
    "response = qa_stuff.run(query)\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "display(Markdown(response))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New chain to return context and sources\n",
    "qa_stuff_with_sources = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query =  \"What is the evidence for an enhanced accretion episode from Sgr A* in 2019?\"\n",
    "\n",
    "# To run the query, we use a different syntax since we're returning more than just the response text\n",
    "responses = qa_stuff_with_sources({\"query\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_documents = responses[\"source_documents\"]\n",
    "source_content = [doc.page_content for doc in source_documents]\n",
    "source_metadata = [doc.metadata for doc in source_documents]\n",
    "\n",
    "# Construct a single string with the LLM output and the source titles and urls\n",
    "def construct_result_with_sources():\n",
    "    result = responses['result']\n",
    "    result += \"\\n\\n\"\n",
    "    result += \"Sources used:\"\n",
    "    for i in range(len(source_content)):    \n",
    "        result += \"\\n\\n\"\n",
    "        result += source_metadata[i]['title']\n",
    "        result += \"\\n\\n\"\n",
    "        return result\n",
    "\n",
    "display(Markdown(construct_result_with_sources()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =  \"What distinguishes a quasar from a normal black hole?\"\n",
    "\n",
    "# To run the query, we use a different syntax since we're returning more than just the response text\n",
    "responses = qa_stuff_with_sources({\"query\": query})\n",
    "\n",
    "source_documents = responses[\"source_documents\"]\n",
    "source_content = [doc.page_content for doc in source_documents]\n",
    "source_metadata = [doc.metadata for doc in source_documents]\n",
    "\n",
    "# Construct a single string with the LLM output and the source titles and urls\n",
    "def construct_result_with_sources():\n",
    "    result = responses['result']\n",
    "    result += \"\\n\\n\"\n",
    "    result += \"Sources used:\"\n",
    "    for i in range(len(source_content)):    \n",
    "        result += \"\\n\\n\"\n",
    "        result += source_metadata[i]['title']\n",
    "        result += \"\\n\\n\"\n",
    "        return result\n",
    "\n",
    "display(Markdown(construct_result_with_sources()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = PGVector.from_documents(\n",
    "#     embedding=embeddings,\n",
    "#     documents=docs,\n",
    "#     collection_name=collection_name,\n",
    "#     connection_string=CONNECTION_STRING,\n",
    "#     pre_delete_collection=False,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "store = PGVector(\n",
    "    collection_name=collection_name,\n",
    "    connection_string=CONNECTION_STRING,\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_texts_df = pd.read_csv('../../data-ingest/data/text/pdf_texts.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Detection of stellar light from quasar host ga...\n",
       "1    Quasars and the\\nIntergalactic Medium at\\nCosm...\n",
       "2    Draft version August 22, 2023\\nTypeset using L...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_texts_df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06f9f18a-bfa6-11ee-8a3d-9801a78f9833',\n",
       " '06f9fdf6-bfa6-11ee-8a3d-9801a78f9833',\n",
       " '06f9fee6-bfa6-11ee-8a3d-9801a78f9833']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.add_texts(pdf_texts_df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"article_title\": {\"type\": \"string\"},\n",
    "        \"authors\": {\"type\": \"string\"},\n",
    "        \"publish_date\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"article_title\", \"authors\", \"publish_date\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['113d7142-bfa8-11ee-8a3d-9801a78f9833',\n",
       " '113d72c8-bfa8-11ee-8a3d-9801a78f9833',\n",
       " '113d7340-bfa8-11ee-8a3d-9801a78f9833']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.add_texts(pdf_texts_df['content'], metadatas=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = store.as_retriever()\n",
    "llm = ChatOpenAI(temperature = 0.0, model = 'gpt-3.5-turbo-16k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dangause/anaconda3/envs/langchain/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# New chain to return context and sources\n",
    "qa_stuff_with_sources = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "query =  \"How does a quasar die?\"\n",
    "\n",
    "# To run the query, we use a different syntax since we're returning more than just the response text\n",
    "responses = qa_stuff_with_sources({\"query\": query})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The exact process of how a quasar dies is not yet fully understood. Quasars are powered by the accretion of matter onto supermassive black holes at the centers of galaxies. This accretion process releases a tremendous amount of energy, causing the quasar to shine brightly. However, quasars are not expected to accrete matter at a constant rate throughout their entire lifetime. Instead, they are believed to exhibit a flickering light curve, with episodes of high and low/no accretion.\n",
       "\n",
       "As a quasar transitions from an active phase to a quiescent phase, its accretion rate decreases, and it gradually fades away. The exact mechanisms that regulate the accretion process and determine the lifetime of a quasar are still the subject of ongoing research. It is possible that factors such as the availability of gas and the dynamics of the surrounding environment play a role in the quasar's demise.\n",
       "\n",
       "Additionally, it is important to note that the term \"quasar\" is often used to refer to the active phase of a supermassive black hole, while the term \"inactive\" or \"dormant\" black hole is used to describe the quiescent phase. During the quiescent phase, the black hole may still exist, but it is not actively accreting matter and therefore does not emit significant amounts of radiation.\n",
       "\n",
       "Sources used:\n",
       "\n",
       "chronicling the reionization history at  6 lesssim z  lesssim 7  with   emergent quasar damping wings\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_documents = responses[\"source_documents\"]\n",
    "source_content = [doc.page_content for doc in source_documents]\n",
    "source_metadata = [doc.metadata for doc in source_documents]\n",
    "\n",
    "# Construct a single string with the LLM output and the source titles and urls\n",
    "def construct_result_with_sources():\n",
    "    result = responses['result']\n",
    "    result += \"\\n\\n\"\n",
    "    result += \"Sources used:\"\n",
    "    for i in range(len(source_content)):    \n",
    "        result += \"\\n\\n\"\n",
    "        result += source_metadata[i]['title']\n",
    "        result += \"\\n\\n\"\n",
    "        return result\n",
    "\n",
    "display(Markdown(construct_result_with_sources()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The exact process of how a quasar dies is not yet fully understood. Quasars are powered by the accretion of matter onto supermassive black holes at the centers of galaxies. This accretion process releases a tremendous amount of energy, causing the quasar to shine brightly. However, quasars are not expected to accrete matter at a constant rate throughout their entire lifetime. Instead, they are believed to exhibit a flickering light curve, with episodes of high and low/no accretion.\\n\\nAs a quasar transitions from an active phase to a quiescent phase, its accretion rate decreases, and it gradually fades away. The exact mechanisms that regulate the accretion process and determine the lifetime of a quasar are still the subject of ongoing research. It is possible that factors such as the availability of gas and the dynamics of the surrounding environment play a role in the quasar\\'s demise.\\n\\nAdditionally, it is important to note that the term \"quasar\" is often used to refer to the active phase of a supermassive black hole, while the term \"inactive\" or \"dormant\" black hole is used to describe the quiescent phase. During the quiescent phase, the black hole may still exist, but it is not actively accreting matter and therefore does not emit significant amounts of radiation.\\n\\nSources used:\\n\\nchronicling the reionization history at  6 lesssim z  lesssim 7  with   emergent quasar damping wings\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_result_with_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ask\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m module_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../src\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;66;03m# or the path to your source code\u001b[39;00m\n\u001b[1;32m      6\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, module_path)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../../src')) # or the path to your source code\n",
    "sys.path.insert(0, module_path)\n",
    "import src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_dir = os.path.split(os.getcwd())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/dangause/Desktop/personal_projects/astro_gpt/astro-buddy/services/gpt-connection'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Settings\nCORS_ORIGINS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nCORS_HEADERS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m settings\n",
      "File \u001b[0;32m~/Desktop/personal_projects/astro_gpt/astro-buddy/services/gpt-connection/src/config.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m         env_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../.env\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m         env_file_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.12/site-packages/pydantic_settings/main.py:71\u001b[0m, in \u001b[0;36mBaseSettings.__init__\u001b[0;34m(__pydantic_self__, _case_sensitive, _env_prefix, _env_file, _env_file_encoding, _env_nested_delimiter, _secrets_dir, **values)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m     __pydantic_self__,\n\u001b[1;32m     62\u001b[0m     _case_sensitive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings_build_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_case_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_case_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_file_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_file_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_secrets_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_secrets_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.12/site-packages/pydantic/main.py:171\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Settings\nCORS_ORIGINS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nCORS_HEADERS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing"
     ]
    }
   ],
   "source": [
    "from src.config import settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for Settings\nCORS_ORIGINS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nCORS_HEADERS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/personal_projects/astro_gpt/astro-buddy/services/gpt-connection/src/config.py:29\u001b[0m\n\u001b[1;32m     25\u001b[0m         env_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;18m__file__\u001b[39m))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/../../.env\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     26\u001b[0m         env_file_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 29\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[43mSettings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.12/site-packages/pydantic_settings/main.py:71\u001b[0m, in \u001b[0;36mBaseSettings.__init__\u001b[0;34m(__pydantic_self__, _case_sensitive, _env_prefix, _env_file, _env_file_encoding, _env_nested_delimiter, _secrets_dir, **values)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m     __pydantic_self__,\n\u001b[1;32m     62\u001b[0m     _case_sensitive: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Uses something other than `self` the first arg to allow \"self\" as a settable attribute\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m__pydantic_self__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settings_build_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_case_sensitive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_case_sensitive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_file_encoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_file_encoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_env_nested_delimiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_secrets_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_secrets_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/langchain/lib/python3.12/site-packages/pydantic/main.py:171\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValidationError\u001b[0m: 2 validation errors for Settings\nCORS_ORIGINS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing\nCORS_HEADERS\n  Field required [type=missing, input_value={'OPENAI_API_KEY': 'sk-7k..._DB_DBNAME': 'postgres'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.6/v/missing"
     ]
    }
   ],
   "source": [
    "import src.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
